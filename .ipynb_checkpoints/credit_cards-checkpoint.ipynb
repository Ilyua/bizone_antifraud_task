{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pprint\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  \n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# стороняя библиотека для работы с несбалансированными датасетами\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# настройки отображения графиков\n",
    "# %config InlineBackend.figure_format = 'svg' \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import mlab\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "%matplotlib inline\n",
    "\n",
    "# увеличим  размер графиков\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 8,4\n",
    "\n",
    "\n",
    "import itertools\n",
    "# для воспроизводимости:\n",
    "r_state = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При первом импорте библиотек появляется предупреждение следующего содержания:\n",
    "\n",
    "\n",
    "/home/ilyua/anaconda3/envs/credit_cards/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29\n",
    "numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
    "  from numpy.core.umath_tests import inner1d\n",
    "  \n",
    "  \n",
    "Судя по пути, это вызвано импортом из ensemble. Я загуглил и нашел, что у кого то тоже возникла такая проблема, но решения не поступило:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/scikit-learn/scikit-learn/issues/11785"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/creditcard.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, что все считалось должным образом: \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сперва посмотрим на распределение меток у целевого класса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(df['Class'].value_counts())\n",
    "# sns.countplot(df['Class']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отчетливо видно, что данные сильно несбалансированы. Для того, чтобы решить эту проблему, я буду использовать три подхода: алгоритмы ADASYN и SMOTE и обучение на сбалансированной подвыборке. Производить оценку моделей буду на тестовой части всей выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим, насколько мошеннические транзакции коррелируют со временем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(df[df['Class']==1]['Time'],100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что имеется два максимума, но на общем фоне они не сильно выделяются."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как пространство признаков изображается при двумерной проекции(на примере признаков 'V11', 'V12', 'V13', 'V14', 'V15') :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# rcParams['figure.figsize'] = 12,12\n",
    "# sns_plot = sns.pairplot(df,vars=['V11', 'V12', 'V13', 'V14', 'V15'],hue=\"Class\",markers=[\"o\", \"s\"])\n",
    "# rcParams['figure.figsize'] = 8,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes=[0,1],title='Confusion matrix',cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_curve(y_test, y_score):\n",
    "    average_precision = average_precision_score(y_test, y_score)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "    plt.step(recall, precision, color='b', alpha=0.2,where='post')\n",
    "    plt.fill_between(recall, precision, step='post', alpha=0.2,color='b')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_estimates(clf,y_test, X_train):\n",
    "    y_score = clf.predict_proba(X_train)[:,1] \n",
    "    fig = plt.figure(figsize=(19,3))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plot_confusion_matrix(confusion_matrix(y_test,clf.predict(X_test)))\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plot_precision_recall_curve(y_test, y_score)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соединим строки поддельных с переводов исходного датасета с таким же количеством неподдельных\n",
    "def create_balanced_data_from_initial(data):\n",
    "    fraud = data[(data['Class']==1)]\n",
    "    not_fraud = data[(data['Class']==0)]\n",
    "\n",
    "    n_fraud = len(fraud)//2\n",
    "\n",
    "    X_original_unb = pd.concat([fraud[n_fraud:].drop(['Class'], axis=1),not_fraud[n_fraud:].drop(['Class'], axis=1)])\n",
    "\n",
    "    y_original_unb = pd.concat([fraud[n_fraud:]['Class'],not_fraud[n_fraud:]['Class']])\n",
    "\n",
    "    X_original_b = pd.concat([fraud[:n_fraud-1].drop(['Class'], axis=1),not_fraud[:n_fraud-1].drop(['Class'], axis=1)])\n",
    "\n",
    "    y_original_b = pd.concat([fraud[:n_fraud-1]['Class'],not_fraud[:n_fraud-1]['Class']])\n",
    "\n",
    "\n",
    "    return X_original_unb,y_original_unb,X_original_b,y_original_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sample(n=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['Class'],axis=1),df['Class'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=r_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Была написана функция потерь заказчика в деньгах. Изначально идея была такова:\n",
    "\n",
    "В случае, если классификатор ошибочно помечает законный перевод как поддельный, то заказчику потребуется потратить некую сумму на разрешение конфликта. Эта сумма состоит из таких затрат как обеспечение работоспособности оборудования, зарплата работников, которые будут управлять этим процеесом и прочие расходы. \n",
    "\n",
    "В случае же, если система не распознает поддельный перевод, то заказчик теряет в размере пропущенного перевода. Но для реализации такой идеи в функции потерь необходим был доступ также к датасету на котором обучается в данный момент модель. Но пакет Scikit-learn не предоставляет такой возможности, он передает в функцию потерь только массивы верных значений и массив значий, предсказанных моделью. Поэтому пришлось исходить из этого и анализировать поддельные переводы, чтобы установить среднюю потерю заказчика при пропуске такого перевода.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на возрастание значение перцентилей при их увеличении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "d = np.sort(df['Amount'])\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "\n",
    "# Percentile values\n",
    "p = np.linspace(99.95, 100, num=100, endpoint=True)#np.arange(95,100,0.01)\n",
    "plt.ticklabel_format(style = 'plain')\n",
    "perc = np.percentile(d, p)\n",
    "\n",
    "plt.plot(p,perc)\n",
    "# Place red dots on the percentiles\n",
    "p = np.linspace(99.95, 100, num=10, endpoint=True)#np.arange(95,100,0.01)\n",
    "plt.ticklabel_format(style = 'plain')\n",
    "perc = np.percentile(d, p)\n",
    "plt.plot(p, perc, 'ro')\n",
    "\n",
    "# # Set tick locations and labels\n",
    "plt.xticks(np.linspace(99.95, 100, num=10, endpoint=True))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что при приближении к 100%, резкий скачок наблюдается после 99.99 перцентиля. То есть, если мы в качестве стоимости поддельного перевода для расчетов возьмем значение этого перцентиля, то мы перестрахуемся настолько, что больше 99% процентов переводов будут приносить меньше ущерба, чем мы рассчитывали. Для нас поддельный перевод отследить важнее, чем исключить полностью ошибки False Positive, поэтому я возьму значение 99.99 перцентиля как ущерб от поддельного перевода, а сумму в 2000 как стоимость разрешения конфликта при неверном отклонении законного перевода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6301.1837249996543"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(df['Amount'], 99.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нет возможности оптимально обратиться к датасету из функции оценки\n",
    "def my_custom_loss_func(y, y_pred,penalty_1,penalty_2): \n",
    "    conf_matrix = confusion_matrix(y, y_pred) \n",
    "    error_1 = conf_matrix[1][0]*penalty_1\n",
    "    error_2 = conf_matrix[0][1]*penalty_2 \n",
    "    return error_1+error_2\n",
    "\n",
    "my_scorer = make_scorer(my_custom_loss_func, greater_is_better=False,penalty_1=6454,penalty_2=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применение алгоритма ADASYN\n",
    "def create_balanced_data_adasyn(x,y):\n",
    "    sm = ADASYN(random_state=12, ratio = 'minority')\n",
    "    X,Y = sm.fit_sample(x, y)\n",
    "    X = pd.DataFrame(X,columns = ['Time','V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'] )\n",
    "    Y = pd.DataFrame(Y,columns = ['Class'])\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка модели на указанных датасетах\n",
    "def estimate_model(clf, X_test, y_test):\n",
    "    print('ROC AUC={0:0.3f}'.format(roc_auc_score(y_test,clf.predict_proba(X_test)[:,1])))\n",
    "    print('Custom loss={0:0.3f}'.format(my_scorer(clf, X_test, y_test)))\n",
    "    print('Average presicion={0:0.3f}'.format(average_precision_score(y_test, clf.predict_proba(X_test)[:,1])))\n",
    "    print(classification_report(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим в рассмотрение параметр class_weight со значением balanced, \n",
    "# чтобы классификатор лучше работал с несбалансированными данными\n",
    "\n",
    "parameters_rfc = {'max_depth': [5,10,None],\n",
    "                  'n_estimators':[20,30,40,50,150],\n",
    "                  'max_features': [5,8,10],\n",
    "                  'class_weight' :['balanced',None]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_xgb= {\n",
    "'n_jobs':[-1],\n",
    "'n_estimators':[40,100,400],\n",
    "'max_depth':range(3,10,2),\n",
    "'min_child_weight':range(1,6,2),\n",
    "'gamma':[i/10.0 for i in range(0,5)],\n",
    "'subsample':[i/10.0 for i in range(8,10)],\n",
    "\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_knn = {'n_neighbors': range(10,30,10),\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_log = {'C': np.linspace(0.1,20,num=20),\n",
    "                  'penalty':['l1', 'l2'],\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_mlp = {'activation':['logistic','relu'], \n",
    "                  'alpha':[1e-5],\n",
    "                  'hidden_layer_sizes':[(256,),(128,256,)],\n",
    "                  'learning_rate':['adaptive']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "# 'rfc':RandomForestClassifier(),\n",
    "# #     'mlp':MLPClassifier(),\n",
    "# 'log':LogisticRegression(),\n",
    "# 'knn':KNeighborsClassifier(),\n",
    "'xgb':XGBClassifier(learning_rate=0.02,  objective='binary:logistic')\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "params ={\n",
    "    'rfc':parameters_rfc,\n",
    "    'knn':parameters_knn,\n",
    "    'log':parameters_log,\n",
    "    'mlp':parameters_mlp,\n",
    "    'xgb':parameters_xgb\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'colsample_bytree': 1.0,\n",
    " 'gamma': 0.5,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 1,\n",
    " 'subsample': 0.6}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рекомендациях к датасету рекомендуется использовать метрику Area Under the Precision-Recall Curve (AUPRC). Чем ближе эта площадь к 1, тем выше качество классификации. Однако в документации пакета Scikit-learn, я увидел предложение, в качестве эквивалентной метрики использовать Average Presicion, потому что площадь под графиком PR Curve, рассчитанная по правилу трапеций может быть излишне оптимистичной. Поэтому для оценки моделей я буду использовать, матрицу ошибок, график Presicion-Recall Curve, метрику Average Presicion и свою оценку потерь заказчика в деньгах. \n",
    "\n",
    "\n",
    "Также, я буду строить график Precision-Recall Curve, поскольку по нему можно наглядно судить о соотношении между метриками Presicion и Recall. Соответственно, чем ближе площадь под графиком к 1, тем лучше качество классификации. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_fuctions=['average_precision',\n",
    "                  my_scorer\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'adasyn':create_balanced_data_adasyn(X_train,y_train)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1madasyn xgb average_precision\u001b[0m\n",
      "\n",
      "------------------\n",
      "\n",
      "Fitting 2 folds for each of 360 candidates, totalling 720 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/credit_cards/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/credit_cards/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/credit_cards/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/credit_cards/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/credit_cards/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/credit_cards/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/credit_cards/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "BOLD = '\\033[1m'\n",
    "END = '\\033[0m'\n",
    "\n",
    "for d_key,d_item in datasets.items():\n",
    "    for c_key,c_item in classifiers.items():\n",
    "        for f in scoring_fuctions:\n",
    "            \n",
    "            print(BOLD+d_key+' '+c_key+' '+str(f)+END)\n",
    "           \n",
    "            print('\\n------------------\\n')\n",
    "            \n",
    "            gcv = GridSearchCV(c_item, params[c_key], n_jobs=-1, cv=skf, verbose=1,scoring=f)       \n",
    "            \n",
    "            X = d_item[0]\n",
    "            y = d_item[1]['Class']\n",
    "           \n",
    "            gcv.fit(X,y)\n",
    "            \n",
    "            \n",
    "            \n",
    "            print(gcv.best_params_)\n",
    "            print('\\n')\n",
    "            \n",
    "            estimate_model(gcv.best_estimator_ ,X_test, y_test)\n",
    "            \n",
    "            plot_estimates(gcv,y_test, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку в прошлом исследовании алгоритм ADASYN показал себя лучше остальных, то я буду использовать его без сравнения со SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При генерации данных ADASYN, необходимо сначала отделить тестовую и проверочную выборки, а затем для тренировочной сгенерировать новые данные. Тк в противном случае, если сначала создать новых данных, а потом разделить выборку, то синтетические данные попадут в проверочный сет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StratifiedKFold - сохраняет процент образцов в тестовом и тренировочных сетах, поэтому такому кросс-валиждатору можно доверять"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# tsne = TSNE(random_state=17)\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(df.drop(['Class'],axis=1))\n",
    "# tsne_representation = tsne.fit_transform(X_scaled)\n",
    "# plt.scatter(tsne_representation[:, 0], tsne_representation[:, 1], \n",
    "#             c=df['Class'].map({0: 'blue', 1: 'orange'}));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нейросеть\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку перед нами не стоит задача распознавания изображений, у нас не так много данных и они не имеют слишком большой размерности, то воспользуемся встроенной в SKlearn нейросетью - MultiLayerClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# scaler = RobustScaler()\n",
    "# for key in sorted(datasets):    \n",
    "#     scaler.fit_transform(datasets[key][0])\n",
    "#     scaler.fit_transform(datasets[key][0])\n",
    "\n",
    "# mlp = MLPClassifier(random_state=r_state)\n",
    "# parameters = {'activation':['logistic','relu'], 'alpha':[1e-5],'hidden_layer_sizes':[(256,),(128,256,)],'learning_rate':['adaptive']}\n",
    "\n",
    "\n",
    "\n",
    "# gcv = GridSearchCV(mlp, parameters, n_jobs=-1, cv=skf, verbose=0,scoring='recall')\n",
    "\n",
    "# fig = plt.figure(figsize=(16,8))\n",
    "# j=1\n",
    "\n",
    "# for key in sorted(datasets):\n",
    "#     print('\\n###############################\\n')\n",
    "    \n",
    "#     gcv.fit(datasets[key][0],datasets[key][1])\n",
    "    \n",
    "#     best_mlp = gcv.best_estimator_   \n",
    "    \n",
    "#     print(key,gcv.best_params_ , gcv.best_score_)\n",
    "    \n",
    "#     estimate_model(gcv.best_estimator_ , scaler.transform(X_original_b),y_original_b, scaler.transform(X_test),y_test)\n",
    "    \n",
    "#     conf_matrix = confusion_matrix(y_test,gcv.best_estimator_.predict(X_test))\n",
    "   \n",
    "#     fig.add_subplot(2,3,j)\n",
    "#     j += 1\n",
    "\n",
    "#     plot_confusion_matrix(conf_matrix, title=key)\n",
    "# plt.show()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Заключение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
